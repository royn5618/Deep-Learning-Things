{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "49688a03",
   "metadata": {},
   "source": [
    "Source - https://nextjournal.com/gkoehler/machine-translation-seq2seq-cpu\n",
    "\n",
    "Data Source - http://www.manythings.org/anki/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeffceb5",
   "metadata": {},
   "source": [
    "# Data Read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f693c5de",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Data/deu-eng/deu.txt', 'r', encoding='utf-8') as f:\n",
    "    lines = f.read().split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c2c35ede",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Go away!\\tSchwirr ab!\\tCC-BY 2.0 (France) Attribution: tatoeba.org #433518 (CK) & #2494158 (Pfirsichbaeumchen)'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines[155]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e1968e2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "227081"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "455bfba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_texts = []\n",
    "target_texts = []\n",
    "input_characters = set()\n",
    "target_characters = set()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35d4f7a2",
   "metadata": {},
   "source": [
    "# Generate Input and Targets\n",
    "\n",
    "Creates a list of uninque characters in the corpur - for input and target separately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "783fc616",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8fff3a51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go. Geh. CC-BY 2.0 (France) Attribution: tatoeba.org #2877272 (CM) & #8597805 (Roujin)\n"
     ]
    }
   ],
   "source": [
    "'''TEST HOW THIS CODE WORKS'''\n",
    "\n",
    "for line in lines[:min(num_samples, len(lines) - 1)]:\n",
    "    input_text, target_text, extra = line.split('\\t')\n",
    "    print(input_text, target_text, extra)\n",
    "    target_text = '\\t' + target_text + '\\n'\n",
    "    input_texts.append(input_text)\n",
    "    target_texts.append(target_text)\n",
    "    \n",
    "    # making set of unique characters - input\n",
    "    for char in input_text:\n",
    "        if char not in input_characters:\n",
    "            input_characters.add(char)\n",
    "    # making set of unique characters - target\n",
    "    for char in target_text:\n",
    "        if char not in target_characters:\n",
    "            target_characters.add(char)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c16caf42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Go.']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "30a5095b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\tGeh.\\n']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e27b42de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'.', 'G', 'o'}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9870c314",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'\\t', '\\n', '.', 'G', 'e', 'h'}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_characters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62bc9f0b",
   "metadata": {},
   "source": [
    "We don't need input and target characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "805f624e",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' ACTUAL EXECUTION '''\n",
    "\n",
    "input_texts = []\n",
    "target_texts = []\n",
    "input_characters = set()\n",
    "target_characters = set()\n",
    "\n",
    "num_samples = 10000\n",
    "\n",
    "for line in lines[:min(num_samples, len(lines) - 1)]:\n",
    "    input_text, target_text, extra = line.split('\\t')\n",
    "    #     print(input_text, target_text, extra)\n",
    "    target_text = '\\t' + target_text + '\\n'\n",
    "    input_texts.append(input_text)\n",
    "    target_texts.append(target_text)\n",
    "    for char in input_text:\n",
    "        if char not in input_characters:\n",
    "            input_characters.add(char)\n",
    "    for char in target_text:\n",
    "        if char not in target_characters:\n",
    "            target_characters.add(char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9437b72d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Y', 'H', 's', 'J', 'Q', '7', 'w', 'o', '4', '1', 'n', 'C', 'T', '-', 'a', 'd', 'c', 'M', 'U', 'E', 'm', ' ', 'S', 'P', 'F', 'e', 'L', 'j', '!', '.', 'z', 'D', '3', 'u', 'v', \"'\", 'x', '9', 'K', 'N', ':', 'p', 'R', 'A', 'G', 'h', '5', '%', '\"', 'y', 'O', '2', 'I', '6', ',', 'g', 'b', '0', '?', 'V', 'W', '8', 't', 'l', 'k', 'f', 'i', 'q', '$', 'B', 'r'}\n"
     ]
    }
   ],
   "source": [
    "print(input_characters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e4187ffc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "71"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(input_characters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ec92f4aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'\\xa0', 'J', '„', 'o', 'U', '\\u202f', ' ', 'S', '3', 'L', 'D', 'u', 'N', '9', \"'\", 'p', 'A', 'h', '5', 'g', '0', 'V', 'W', '8', 'Ü', 'Q', 'w', '1', 'a', 'M', 'c', 'ü', 'P', '\\n', 'F', 'O', 'y', ',', 'Ä', 'q', 'H', 'ö', '4', 'n', 'T', '-', 'j', 'e', 'z', 'x', ':', '2', 'I', 'b', '?', 't', 'k', 'Y', 'Ö', 's', '“', '7', '\\t', 'C', 'd', 'E', 'm', '!', '.', 'v', 'Z', 'K', 'R', 'G', 'ß', '%', '’', 'ä', '6', 'l', 'f', '$', 'i', 'B', 'r'}\n"
     ]
    }
   ],
   "source": [
    "print(target_characters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ecd30bda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "85"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(target_characters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1196ca8d",
   "metadata": {},
   "source": [
    "# Get Configs for this Corpus\n",
    "\n",
    "Here, we obtain\n",
    "\n",
    "1. number of input texts (should be equal to number of samples)\n",
    "\n",
    "2. Total number of input characters for encoder model\n",
    "\n",
    "3. Total number of output characters for decoder model\n",
    "\n",
    "4. Maximum sequence length for input and output for binarised one-hot encoding of te texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "942a3b13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: 10000\n",
      "Number of unique input tokens (characters): 71\n",
      "Number of unique output tokens (characters): 85\n",
      "Max sequence length for inputs: 15\n",
      "Max sequence length for outputs: 45\n"
     ]
    }
   ],
   "source": [
    "input_characters = sorted(list(input_characters))\n",
    "target_characters = sorted(list(target_characters))\n",
    "num_encoder_tokens = len(input_characters)\n",
    "num_decoder_tokens = len(target_characters)\n",
    "max_encoder_seq_length = max([len(txt) for txt in input_texts\n",
    "                              ])  # length includes spaces\n",
    "max_decoder_seq_length = max([len(txt) for txt in target_texts\n",
    "                              ])  # length includes spaces\n",
    "\n",
    "print('Number of samples:', len(input_texts))  # we set this earlier\n",
    "print('Number of unique input tokens (characters):', num_encoder_tokens)\n",
    "print('Number of unique output tokens (characters):', num_decoder_tokens)\n",
    "print('Max sequence length for inputs:', max_encoder_seq_length)\n",
    "print('Max sequence length for outputs:', max_decoder_seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "47ca8c74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go on.\n",
      "6\n",
      "Hello!\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "# # TEST - Length includes spaces\n",
    "# for txt in input_texts[15:17]:\n",
    "#     print(txt)\n",
    "#     print(len(txt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "91a498a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# one-hot encoding of the characters - basically creating word embeddings\n",
    "\n",
    "input_token_index = dict([(char, i)\n",
    "                          for i, char in enumerate(input_characters)])\n",
    "target_token_index = dict([(char, i)\n",
    "                           for i, char in enumerate(target_characters)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "55108153",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "encoder_input_data = np.zeros(\n",
    "    (len(input_texts), max_encoder_seq_length, num_encoder_tokens),\n",
    "    dtype='float32')\n",
    "decoder_input_data = np.zeros(\n",
    "    (len(input_texts), max_decoder_seq_length, num_decoder_tokens),\n",
    "    dtype='float32')\n",
    "decoder_target_data = np.zeros(\n",
    "    (len(input_texts), max_decoder_seq_length, num_decoder_tokens),\n",
    "    dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "2068556c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (input_text, target_text) in enumerate(zip(input_texts, target_texts)):\n",
    "    for t, char in enumerate(input_text):\n",
    "        encoder_input_data[i, t, input_token_index[char]] = 1.\n",
    "    for t, char in enumerate(target_text):\n",
    "        # decoder_target_data is ahead of decoder_input_data by one timestep\n",
    "        decoder_input_data[i, t, target_token_index[char]] = 1.\n",
    "        if t > 0:\n",
    "            # decoder_target_data will be ahead by one timestep\n",
    "            # and will not include the start character.\n",
    "            decoder_target_data[i, t - 1, target_token_index[char]] = 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b99e6aea",
   "metadata": {},
   "source": [
    "## Example - Input Characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "256ac0c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hi.'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_texts[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "e657c8d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' ', '!', '\"', '$', '%', \"'\", ',', '-', '.', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'Y', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n"
     ]
    }
   ],
   "source": [
    "print(input_characters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "7bcca625",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_h = input_characters.index('H')\n",
    "index_h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "e0785efd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_input_data[1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "2e5573fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_input_data[1][0][index_h]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "b18459ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15, 71)"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_input_data[1].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a364a588",
   "metadata": {},
   "source": [
    "## Example - Output Characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "30866da2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\tHallo!\\n'"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_texts[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "57ecaeb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t: (array([0], dtype=int64),)\n",
      "H: (array([29], dtype=int64),)\n",
      "a: (array([47], dtype=int64),)\n",
      "l: (array([58], dtype=int64),)\n",
      "l: (array([58], dtype=int64),)\n",
      "o: (array([61], dtype=int64),)\n",
      "!: (array([3], dtype=int64),)\n",
      "\n",
      ": (array([1], dtype=int64),)\n"
     ]
    }
   ],
   "source": [
    "for each_char in target_texts[1]:\n",
    "    print(\"{}: {}\".format(each_char, np.where(np.array(target_characters) == each_char)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "3cdb2e41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\t', '\\n', ' ', '!', '$', '%', \"'\", ',', '-', '.', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '\\xa0', 'Ä', 'Ö', 'Ü', 'ß', 'ä', 'ö', 'ü', '’', '“', '„', '\\u202f']\n"
     ]
    }
   ],
   "source": [
    "print(target_characters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "46e5244a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "29\n",
      "47\n",
      "58\n",
      "58\n",
      "61\n",
      "3\n",
      "1\n",
      "Number of arrays:  45\n"
     ]
    }
   ],
   "source": [
    "for array_ in decoder_input_data[1]:\n",
    "    idx = np.where(array_ == 1)\n",
    "    try:\n",
    "        if idx:\n",
    "            print(idx[0][0])\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "print(\"Number of arrays: \", len(decoder_input_data[1])) # Should be equal to max_decoder_seq_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "8366f000",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29\n",
      "47\n",
      "58\n",
      "58\n",
      "61\n",
      "3\n",
      "1\n",
      "Number of arrays:  45\n"
     ]
    }
   ],
   "source": [
    "# Expected the array to start from 29, since it is ahead by one step\n",
    "\n",
    "for array_ in decoder_target_data[1]:\n",
    "    idx = np.where(array_ == 1)\n",
    "    try:\n",
    "        if idx:\n",
    "            print(idx[0][0])\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "print(\"Number of arrays: \", len(decoder_target_data[1])) # Should be equal to max_decoder_seq_length"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60244f98",
   "metadata": {},
   "source": [
    "# Building the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "d9af06f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras, tensorflow\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, LSTM, Dense\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "86b885e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64  # batch size for training\n",
    "epochs = 100  # number of epochs to train for\n",
    "lstm_units = 256  # latent dimensionality of the encoding space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "ddd5ae00",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_inputs = Input(shape=(None, num_encoder_tokens))  # input texts\n",
    "encoder = LSTM(lstm_units, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder(\n",
    "    encoder_inputs\n",
    ")  # Gets back the hidden and cell states to feed in to the decoder\n",
    "encoder_states = [\n",
    "    state_h, state_c\n",
    "]  # obtained the encoder vector states cz only interested in the state vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "496d9652",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_inputs = Input(shape=(None, num_decoder_tokens))  # the target texts\n",
    "decoder_lstm = LSTM(lstm_units, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _ = decoder_lstm(decoder_inputs,\n",
    "                                     initial_state=encoder_states)\n",
    "decoder_dense = Dense(num_decoder_tokens, activation='softmax')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "0e65d9b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(inputs=[encoder_inputs, decoder_inputs], outputs=decoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "7a6a94f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_4 (InputLayer)            [(None, None, 71)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_5 (InputLayer)            [(None, None, 85)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   [(None, 256), (None, 335872      input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   [(None, None, 256),  350208      input_5[0][0]                    \n",
      "                                                                 lstm_1[0][1]                     \n",
      "                                                                 lstm_1[0][2]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, None, 85)     21845       lstm_2[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 707,925\n",
      "Trainable params: 707,925\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "79dfac39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "125/125 [==============================] - 31s 128ms/step - loss: 1.3477 - val_loss: 1.3707\n",
      "Epoch 2/100\n",
      "125/125 [==============================] - 16s 131ms/step - loss: 1.1899 - val_loss: 1.2650\n",
      "Epoch 3/100\n",
      "125/125 [==============================] - 16s 126ms/step - loss: 1.1103 - val_loss: 1.2581\n",
      "Epoch 4/100\n",
      "125/125 [==============================] - 16s 124ms/step - loss: 1.0539 - val_loss: 1.1670\n",
      "Epoch 5/100\n",
      "125/125 [==============================] - 16s 126ms/step - loss: 1.0163 - val_loss: 1.1202\n",
      "Epoch 6/100\n",
      "125/125 [==============================] - 16s 126ms/step - loss: 0.9741 - val_loss: 1.0967\n",
      "Epoch 7/100\n",
      "125/125 [==============================] - 16s 125ms/step - loss: 0.9416 - val_loss: 1.0701\n",
      "Epoch 8/100\n",
      "125/125 [==============================] - 15s 124ms/step - loss: 0.9035 - val_loss: 1.0060\n",
      "Epoch 9/100\n",
      "125/125 [==============================] - 16s 126ms/step - loss: 0.8838 - val_loss: 1.0188\n",
      "Epoch 10/100\n",
      "125/125 [==============================] - 16s 125ms/step - loss: 0.8531 - val_loss: 1.0089\n",
      "Epoch 11/100\n",
      "125/125 [==============================] - 16s 126ms/step - loss: 0.8332 - val_loss: 1.0166\n",
      "Epoch 12/100\n",
      "125/125 [==============================] - 16s 125ms/step - loss: 0.8133 - val_loss: 0.9815\n",
      "Epoch 13/100\n",
      "125/125 [==============================] - 16s 126ms/step - loss: 0.8005 - val_loss: 0.9368\n",
      "Epoch 14/100\n",
      "125/125 [==============================] - 16s 132ms/step - loss: 0.7767 - val_loss: 0.9370\n",
      "Epoch 15/100\n",
      "125/125 [==============================] - 16s 129ms/step - loss: 0.7600 - val_loss: 0.9072\n",
      "Epoch 16/100\n",
      "125/125 [==============================] - 16s 126ms/step - loss: 0.7407 - val_loss: 0.9087\n",
      "Epoch 17/100\n",
      "125/125 [==============================] - 16s 129ms/step - loss: 0.7195 - val_loss: 0.8848\n",
      "Epoch 18/100\n",
      "125/125 [==============================] - 16s 130ms/step - loss: 0.6920 - val_loss: 0.8209\n",
      "Epoch 19/100\n",
      "125/125 [==============================] - 16s 130ms/step - loss: 0.6792 - val_loss: 0.8028\n",
      "Epoch 20/100\n",
      "125/125 [==============================] - 16s 127ms/step - loss: 0.6622 - val_loss: 0.8123\n",
      "Epoch 21/100\n",
      "125/125 [==============================] - 16s 127ms/step - loss: 0.6542 - val_loss: 0.8007\n",
      "Epoch 22/100\n",
      "125/125 [==============================] - 16s 128ms/step - loss: 0.6461 - val_loss: 0.7720\n",
      "Epoch 23/100\n",
      "125/125 [==============================] - 16s 129ms/step - loss: 0.6356 - val_loss: 0.7891\n",
      "Epoch 24/100\n",
      "125/125 [==============================] - 16s 129ms/step - loss: 0.6274 - val_loss: 0.7622\n",
      "Epoch 25/100\n",
      "125/125 [==============================] - 16s 130ms/step - loss: 0.6156 - val_loss: 0.7727\n",
      "Epoch 26/100\n",
      "125/125 [==============================] - 16s 128ms/step - loss: 0.6131 - val_loss: 0.7496\n",
      "Epoch 27/100\n",
      "125/125 [==============================] - 16s 127ms/step - loss: 0.6071 - val_loss: 0.7547\n",
      "Epoch 28/100\n",
      "125/125 [==============================] - 16s 128ms/step - loss: 0.5981 - val_loss: 0.7446\n",
      "Epoch 29/100\n",
      "125/125 [==============================] - 16s 126ms/step - loss: 0.5880 - val_loss: 0.7377\n",
      "Epoch 30/100\n",
      "125/125 [==============================] - 16s 126ms/step - loss: 0.5872 - val_loss: 0.7414\n",
      "Epoch 31/100\n",
      "125/125 [==============================] - 16s 128ms/step - loss: 0.5815 - val_loss: 0.7327\n",
      "Epoch 32/100\n",
      "125/125 [==============================] - 16s 130ms/step - loss: 0.5774 - val_loss: 0.7236\n",
      "Epoch 33/100\n",
      "125/125 [==============================] - 17s 132ms/step - loss: 0.5677 - val_loss: 0.7382\n",
      "Epoch 34/100\n",
      "125/125 [==============================] - 16s 128ms/step - loss: 0.5601 - val_loss: 0.7242\n",
      "Epoch 35/100\n",
      "125/125 [==============================] - 16s 131ms/step - loss: 0.5606 - val_loss: 0.7150\n",
      "Epoch 36/100\n",
      "125/125 [==============================] - 16s 128ms/step - loss: 0.5500 - val_loss: 0.7309\n",
      "Epoch 37/100\n",
      "125/125 [==============================] - 16s 129ms/step - loss: 0.5464 - val_loss: 0.7045\n",
      "Epoch 38/100\n",
      "125/125 [==============================] - 16s 130ms/step - loss: 0.5322 - val_loss: 0.7243\n",
      "Epoch 39/100\n",
      "125/125 [==============================] - 16s 131ms/step - loss: 0.5395 - val_loss: 0.7275\n",
      "Epoch 40/100\n",
      "125/125 [==============================] - 16s 129ms/step - loss: 0.5354 - val_loss: 0.7064\n",
      "Epoch 41/100\n",
      "125/125 [==============================] - 16s 130ms/step - loss: 0.5252 - val_loss: 0.6966\n",
      "Epoch 42/100\n",
      "125/125 [==============================] - 16s 128ms/step - loss: 0.5251 - val_loss: 0.6928\n",
      "Epoch 43/100\n",
      "125/125 [==============================] - 16s 129ms/step - loss: 0.5129 - val_loss: 0.6877\n",
      "Epoch 44/100\n",
      "125/125 [==============================] - 16s 129ms/step - loss: 0.5166 - val_loss: 0.6916\n",
      "Epoch 45/100\n",
      "125/125 [==============================] - 16s 127ms/step - loss: 0.5106 - val_loss: 0.6836\n",
      "Epoch 46/100\n",
      "125/125 [==============================] - 16s 128ms/step - loss: 0.5110 - val_loss: 0.6863\n",
      "Epoch 47/100\n",
      "125/125 [==============================] - 16s 128ms/step - loss: 0.5091 - val_loss: 0.6983\n",
      "Epoch 48/100\n",
      "125/125 [==============================] - 16s 129ms/step - loss: 0.5015 - val_loss: 0.6879\n",
      "Epoch 49/100\n",
      "125/125 [==============================] - 16s 128ms/step - loss: 0.5008 - val_loss: 0.6758\n",
      "Epoch 50/100\n",
      "125/125 [==============================] - 16s 127ms/step - loss: 0.4963 - val_loss: 0.6818\n",
      "Epoch 51/100\n",
      "125/125 [==============================] - 17s 135ms/step - loss: 0.4923 - val_loss: 0.6770\n",
      "Epoch 52/100\n",
      "125/125 [==============================] - 16s 128ms/step - loss: 0.4930 - val_loss: 0.6736\n",
      "Epoch 53/100\n",
      "125/125 [==============================] - 16s 128ms/step - loss: 0.4858 - val_loss: 0.6882\n",
      "Epoch 54/100\n",
      "125/125 [==============================] - 16s 128ms/step - loss: 0.4901 - val_loss: 0.6682\n",
      "Epoch 55/100\n",
      "125/125 [==============================] - 16s 131ms/step - loss: 0.4769 - val_loss: 0.6812\n",
      "Epoch 56/100\n",
      "125/125 [==============================] - 16s 128ms/step - loss: 0.4791 - val_loss: 0.6665\n",
      "Epoch 57/100\n",
      "125/125 [==============================] - 16s 129ms/step - loss: 0.4771 - val_loss: 0.6731\n",
      "Epoch 58/100\n",
      "125/125 [==============================] - 16s 128ms/step - loss: 0.4734 - val_loss: 0.6726\n",
      "Epoch 59/100\n",
      "125/125 [==============================] - 16s 128ms/step - loss: 0.4654 - val_loss: 0.6666\n",
      "Epoch 60/100\n",
      "125/125 [==============================] - 16s 126ms/step - loss: 0.4706 - val_loss: 0.6647\n",
      "Epoch 61/100\n",
      "125/125 [==============================] - 16s 126ms/step - loss: 0.4656 - val_loss: 0.6716\n",
      "Epoch 62/100\n",
      "125/125 [==============================] - 16s 127ms/step - loss: 0.4633 - val_loss: 0.6812\n",
      "Epoch 63/100\n",
      "125/125 [==============================] - 16s 127ms/step - loss: 0.4581 - val_loss: 0.6660\n",
      "Epoch 64/100\n",
      "125/125 [==============================] - 16s 127ms/step - loss: 0.4553 - val_loss: 0.6695\n",
      "Epoch 65/100\n",
      "125/125 [==============================] - 16s 128ms/step - loss: 0.4522 - val_loss: 0.6595\n",
      "Epoch 66/100\n",
      "125/125 [==============================] - 16s 128ms/step - loss: 0.4546 - val_loss: 0.6663\n",
      "Epoch 67/100\n",
      "125/125 [==============================] - 16s 127ms/step - loss: 0.4470 - val_loss: 0.6668\n",
      "Epoch 68/100\n",
      "125/125 [==============================] - 16s 127ms/step - loss: 0.4492 - val_loss: 0.6576\n",
      "Epoch 69/100\n",
      "125/125 [==============================] - 16s 127ms/step - loss: 0.4473 - val_loss: 0.6578\n",
      "Epoch 70/100\n",
      "125/125 [==============================] - 17s 133ms/step - loss: 0.4421 - val_loss: 0.6565\n",
      "Epoch 71/100\n",
      "125/125 [==============================] - 16s 127ms/step - loss: 0.4404 - val_loss: 0.6704\n",
      "Epoch 72/100\n",
      "125/125 [==============================] - 16s 126ms/step - loss: 0.4372 - val_loss: 0.6714\n",
      "Epoch 73/100\n",
      "125/125 [==============================] - 16s 127ms/step - loss: 0.4363 - val_loss: 0.6531\n",
      "Epoch 74/100\n",
      "125/125 [==============================] - 16s 128ms/step - loss: 0.4384 - val_loss: 0.6511\n",
      "Epoch 75/100\n",
      "125/125 [==============================] - 16s 127ms/step - loss: 0.4338 - val_loss: 0.6543\n",
      "Epoch 76/100\n",
      "125/125 [==============================] - 16s 127ms/step - loss: 0.4321 - val_loss: 0.6615\n",
      "Epoch 77/100\n",
      "125/125 [==============================] - 15s 123ms/step - loss: 0.4319 - val_loss: 0.6565\n",
      "Epoch 78/100\n",
      "125/125 [==============================] - 15s 123ms/step - loss: 0.4316 - val_loss: 0.6555\n",
      "Epoch 79/100\n",
      "125/125 [==============================] - 15s 122ms/step - loss: 0.4264 - val_loss: 0.6522\n",
      "Epoch 80/100\n",
      "125/125 [==============================] - 15s 122ms/step - loss: 0.4253 - val_loss: 0.6527\n",
      "Epoch 81/100\n",
      "125/125 [==============================] - 15s 122ms/step - loss: 0.4235 - val_loss: 0.6574\n",
      "Epoch 82/100\n",
      "125/125 [==============================] - 15s 123ms/step - loss: 0.4222 - val_loss: 0.6469\n",
      "Epoch 83/100\n",
      "125/125 [==============================] - 15s 122ms/step - loss: 0.4188 - val_loss: 0.6722\n",
      "Epoch 84/100\n",
      "125/125 [==============================] - 15s 123ms/step - loss: 0.4196 - val_loss: 0.6600\n",
      "Epoch 85/100\n",
      "125/125 [==============================] - 16s 131ms/step - loss: 0.4203 - val_loss: 0.6536\n",
      "Epoch 86/100\n",
      "125/125 [==============================] - 15s 124ms/step - loss: 0.4183 - val_loss: 0.6728\n",
      "Epoch 87/100\n",
      "125/125 [==============================] - 15s 123ms/step - loss: 0.4145 - val_loss: 0.6472\n",
      "Epoch 88/100\n",
      "125/125 [==============================] - 15s 124ms/step - loss: 0.4169 - val_loss: 0.6677\n",
      "Epoch 89/100\n",
      "125/125 [==============================] - 16s 129ms/step - loss: 0.4112 - val_loss: 0.6535\n",
      "Epoch 90/100\n",
      "125/125 [==============================] - 15s 124ms/step - loss: 0.4112 - val_loss: 0.6512\n",
      "Epoch 91/100\n",
      "125/125 [==============================] - 15s 123ms/step - loss: 0.4033 - val_loss: 0.6493\n",
      "Epoch 92/100\n",
      "125/125 [==============================] - 16s 126ms/step - loss: 0.4084 - val_loss: 0.6492\n",
      "Epoch 93/100\n",
      "125/125 [==============================] - 16s 125ms/step - loss: 0.4085 - val_loss: 0.6570\n",
      "Epoch 94/100\n",
      "125/125 [==============================] - 15s 124ms/step - loss: 0.4026 - val_loss: 0.6579\n",
      "Epoch 95/100\n",
      "125/125 [==============================] - 15s 124ms/step - loss: 0.4109 - val_loss: 0.6627\n",
      "Epoch 96/100\n",
      "125/125 [==============================] - 15s 124ms/step - loss: 0.4055 - val_loss: 0.6614\n",
      "Epoch 97/100\n",
      "125/125 [==============================] - 15s 124ms/step - loss: 0.4019 - val_loss: 0.6688\n",
      "Epoch 98/100\n",
      "125/125 [==============================] - 15s 123ms/step - loss: 0.4000 - val_loss: 0.6513\n",
      "Epoch 99/100\n",
      "125/125 [==============================] - 15s 123ms/step - loss: 0.3981 - val_loss: 0.6518\n",
      "Epoch 100/100\n",
      "125/125 [==============================] - 15s 124ms/step - loss: 0.4019 - val_loss: 0.6426\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "Unable to create file (unable to open file: name = '/results/seq2seq_eng-ger.h5', errno = 2, error message = 'No such file or directory', flags = 13, o_flags = 302)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-150-0f76b8d2d249>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m           \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m           validation_split=0.2)\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'/results/seq2seq_eng-ger.h5'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(self, filepath, overwrite, include_optimizer, save_format, signatures, options, save_traces)\u001b[0m\n\u001b[0;32m   2084\u001b[0m     \"\"\"\n\u001b[0;32m   2085\u001b[0m     \u001b[1;31m# pylint: enable=line-too-long\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2086\u001b[1;33m     save.save_model(self, filepath, overwrite, include_optimizer, save_format,\n\u001b[0m\u001b[0;32m   2087\u001b[0m                     signatures, options, save_traces)\n\u001b[0;32m   2088\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\saving\\save.py\u001b[0m in \u001b[0;36msave_model\u001b[1;34m(model, filepath, overwrite, include_optimizer, save_format, signatures, options, save_traces)\u001b[0m\n\u001b[0;32m    144\u001b[0m           \u001b[1;34m'to the Tensorflow SavedModel format (by setting save_format=\"tf\") '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    145\u001b[0m           'or using `save_weights`.')\n\u001b[1;32m--> 146\u001b[1;33m     hdf5_format.save_model_to_hdf5(\n\u001b[0m\u001b[0;32m    147\u001b[0m         model, filepath, overwrite, include_optimizer)\n\u001b[0;32m    148\u001b[0m   \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\saving\\hdf5_format.py\u001b[0m in \u001b[0;36msave_model_to_hdf5\u001b[1;34m(model, filepath, overwrite, include_optimizer)\u001b[0m\n\u001b[0;32m    101\u001b[0m       \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mv1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgfile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMakeDirs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdirpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    102\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 103\u001b[1;33m     \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh5py\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'w'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    104\u001b[0m     \u001b[0mopened_new_file\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    105\u001b[0m   \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\h5py\\_hl\\files.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, fs_strategy, fs_persist, fs_threshold, **kwds)\u001b[0m\n\u001b[0;32m    422\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mphil\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    423\u001b[0m                 \u001b[0mfapl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmake_fapl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdriver\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlibver\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrdcc_nslots\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrdcc_nbytes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrdcc_w0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 424\u001b[1;33m                 fid = make_fid(name, mode, userblock_size,\n\u001b[0m\u001b[0;32m    425\u001b[0m                                fapl, fcpl=make_fcpl(track_order=track_order, fs_strategy=fs_strategy,\n\u001b[0;32m    426\u001b[0m                                fs_persist=fs_persist, fs_threshold=fs_threshold),\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\h5py\\_hl\\files.py\u001b[0m in \u001b[0;36mmake_fid\u001b[1;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[0;32m    194\u001b[0m         \u001b[0mfid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mACC_EXCL\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfcpl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfcpl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'w'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 196\u001b[1;33m         \u001b[0mfid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mACC_TRUNC\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfcpl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfcpl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    197\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'a'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m         \u001b[1;31m# Open in append mode (read/write).\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mh5py\\_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mh5py\\_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mh5py\\h5f.pyx\u001b[0m in \u001b[0;36mh5py.h5f.create\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: Unable to create file (unable to open file: name = '/results/seq2seq_eng-ger.h5', errno = 2, error message = 'No such file or directory', flags = 13, o_flags = 302)"
     ]
    }
   ],
   "source": [
    "model.fit([encoder_input_data, decoder_input_data], decoder_target_data,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "677dd790",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('/Models/seq2seq_eng-ger.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a32124d",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a93e5ecd",
   "metadata": {},
   "source": [
    "## Load from Saved Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "02541cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "## LOAD FROM SAVED MODEL\n",
    "\n",
    "# model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "# model.compile(optimizer='rmsprop', loss='categorical_crossentropy')\n",
    "# model.load_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "67be64a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_model = Model(encoder_inputs, encoder_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "80d423e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_state_input_h = Input(shape=(lstm_units, ))\n",
    "decoder_state_input_c = Input(shape=(lstm_units, ))\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "1690f6c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_outputs, state_h, state_c = decoder_lstm(\n",
    "    decoder_inputs, initial_state=decoder_states_inputs)\n",
    "decoder_states = [state_h, state_c]\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "decoder_model = Model([decoder_inputs] + decoder_states_inputs,\n",
    "                      [decoder_outputs] + decoder_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "9ec61e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reverse-lookup token index to turn sequences back to characters\n",
    "\n",
    "reverse_input_char_index = dict(\n",
    "    (i, char) for char, i in input_token_index.items())\n",
    "reverse_target_char_index = dict(\n",
    "    (i, char) for char, i in target_token_index.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "687a63dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 15, 71)\n",
      "[[[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]]\n"
     ]
    }
   ],
   "source": [
    "input_sentence = \"How are you?\"\n",
    "test_sentence_tokenized = np.zeros(\n",
    "    (1, max_encoder_seq_length, num_encoder_tokens), dtype='float32')\n",
    "print(test_sentence_tokenized.shape) \n",
    "\n",
    "for t, char in enumerate(input_sentence):\n",
    "    test_sentence_tokenized[0, t, input_token_index[char]] = 1.\n",
    "print(test_sentence_tokenized) # the binarised one-hot encoded form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "b0d4c75f",
   "metadata": {},
   "outputs": [],
   "source": [
    "states_value = encoder_model.predict(test_sentence_tokenized) # getting the states values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "4d7772ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 256)"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# states_value is a list with two elements\n",
    "\n",
    "states_value[0].shape # recall lstm layer units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "ae9e5fda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0.]]])"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# generate empty target sequence\n",
    "target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "target_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "fbd87ade",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0.]]])"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add 1 to indicate [START] or \\t\n",
    "target_seq[0, 0, target_token_index['\\t']] = 1.\n",
    "target_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "01a97530",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1, 85)"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_seq.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "12844875",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[3.76637938e-04, 9.58756063e-05, 3.31804156e-04, 2.97309336e-04,\n",
       "         1.14638271e-04, 9.66965308e-05, 9.81786361e-05, 1.78010625e-04,\n",
       "         6.99794618e-05, 5.93443692e-05, 1.65433070e-04, 3.67576249e-05,\n",
       "         5.57057247e-05, 2.16987301e-05, 3.71472452e-05, 1.93148371e-04,\n",
       "         1.62555123e-04, 1.08228276e-04, 4.69805527e-05, 2.52005702e-04,\n",
       "         3.42866027e-04, 1.91174586e-05, 1.54850539e-03, 1.13971392e-03,\n",
       "         9.27087895e-05, 8.56718887e-03, 2.10939441e-03, 4.94942418e-04,\n",
       "         3.12250981e-04, 1.15063193e-03, 1.58461800e-03, 6.51997048e-04,\n",
       "         8.86965368e-04, 9.14979319e-04, 8.97095480e-04, 2.63134460e-03,\n",
       "         2.64438451e-04, 1.70949686e-04, 1.40627686e-04, 1.47998182e-03,\n",
       "         5.60146524e-03, 2.53967335e-03, 1.41218153e-03, 1.70434956e-04,\n",
       "         9.53538597e-01, 8.70950025e-05, 4.61355579e-04, 7.01689860e-05,\n",
       "         4.17333613e-05, 9.90965418e-05, 1.19104938e-04, 4.44617384e-04,\n",
       "         7.30814718e-05, 1.07304550e-04, 1.89090191e-04, 1.18108036e-03,\n",
       "         1.94124877e-04, 4.54597903e-05, 1.97779300e-04, 1.94782479e-04,\n",
       "         5.15104563e-04, 3.18619772e-04, 1.84295277e-05, 2.30544392e-04,\n",
       "         4.95765358e-04, 1.07293701e-04, 3.53506271e-04, 2.00113718e-04,\n",
       "         3.19288956e-04, 1.47347324e-04, 6.69677174e-05, 9.65682484e-05,\n",
       "         3.90238158e-04, 1.46195074e-04, 1.72943342e-04, 3.53304727e-04,\n",
       "         3.15107813e-04, 1.02531623e-04, 8.76997728e-05, 1.47191138e-04,\n",
       "         1.48720108e-04, 1.45710685e-04, 5.31186924e-05, 1.98367798e-05,\n",
       "         8.13269944e-05]]], dtype=float32)"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
    "output_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "42bc820a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1, 85)"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_tokens.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "8eeaaed6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True])"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_tokens[0, -1, :] == output_tokens[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "6284a26a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_token_index = np.argmax(output_tokens[0, -1, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "c2739e66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled_token_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "9288ae2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # To explain argmax\n",
    "# np.where(output_tokens[0][0] == np.max(output_tokens[0, -1, :]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "1c8da19a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'W'"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled_char = reverse_target_char_index[sampled_token_index] # Get the character from the dictionary\n",
    "sampled_char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "252fcfec",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded_sentence = ''\n",
    "decoded_sentence += sampled_char # add the character\n",
    "# This will be in a while loop later to keep adding until the [END] is reached"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "5e3a620c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STOP CONDITION  - if the character is \\n or the lenth of the sentence if more than the max target inputs we used for training\n",
    "if (sampled_char == '\\n' or len(decoded_sentence) > max_decoder_seq_length):\n",
    "    stop_condition = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "4d4126ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# update the target sequence (length 1).\n",
    "target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "target_seq[0, 0, sampled_token_index] = 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "5534021b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0.]]])"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "e23f72f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "states_value = [h, c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "2a0c5c84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Wi'"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
    "    \n",
    "# sample a token and add the corresponding character to the \n",
    "# decoded sequence\n",
    "sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "sampled_char = reverse_target_char_index[sampled_token_index]\n",
    "decoded_sentence += sampled_char\n",
    "decoded_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "fe564454",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Putting all of that together '''\n",
    "\n",
    "def decode_sequence(input_seq):\n",
    "    # encode the input sequence to get the internal state vectors.\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "\n",
    "    # generate empty target sequence of length 1 with only the start character\n",
    "    target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "    target_seq[0, 0, target_token_index['\\t']] = 1\n",
    "\n",
    "    # output sequence loop\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    while not stop_condition:\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] +\n",
    "                                                    states_value)\n",
    "\n",
    "        # sample a token and add the corresponding character to the\n",
    "        # decoded sequence\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_char = reverse_target_char_index[sampled_token_index]\n",
    "        decoded_sentence += sampled_char\n",
    "        # check for the exit condition: either hitting max length\n",
    "        # or predicting the 'stop' character\n",
    "        if (sampled_char == '\\n' or len(decoded_sentence) > max_decoder_seq_length):\n",
    "            stop_condition = True\n",
    "\n",
    "        # update the target sequence (length 1).\n",
    "        target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "        target_seq[0, 0, sampled_token_index] = 1.\n",
    "\n",
    "        # update states\n",
    "        states_value = [h, c]\n",
    "\n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "77cd1198",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How are you?\n",
      "Wie geht es auf.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "input_sentence = \"How are you?\"\n",
    "test_sentence_tokenized = np.zeros(\n",
    "    (1, max_encoder_seq_length, num_encoder_tokens), dtype='float32')\n",
    "for t, char in enumerate(input_sentence):\n",
    "    test_sentence_tokenized[0, t, input_token_index[char]] = 1.\n",
    "print(input_sentence)\n",
    "print(decode_sequence(test_sentence_tokenized))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "dd0a3043",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-\n",
      "Input sentence: Wow!\n",
      "Decoded sentence: Wonnerten?\n",
      "\n",
      "Target sentence: Donnerwetter!\n",
      "-\n",
      "Input sentence: Fire!\n",
      "Decoded sentence: Gehen.\n",
      "\n",
      "Target sentence: Feuer!\n",
      "-\n",
      "Input sentence: Help!\n",
      "Decoded sentence: Zie in der auf.\n",
      "\n",
      "Target sentence: Hilfe!\n",
      "-\n",
      "Input sentence: Help!\n",
      "Decoded sentence: Zie in der auf.\n",
      "\n",
      "Target sentence: Zu Hülf!\n"
     ]
    }
   ],
   "source": [
    "for seq_index in range(6, 10):\n",
    "    input_seq = encoder_input_data[seq_index:seq_index + 1]\n",
    "    decoded_sentence = decode_sequence(input_seq)\n",
    "    print('-')\n",
    "    print('Input sentence:', input_texts[seq_index])\n",
    "    print('Decoded sentence:', decoded_sentence)\n",
    "    print('Target sentence:', target_texts[seq_index].strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cb4f456",
   "metadata": {},
   "source": [
    " # Model Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "a077e221",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_input_texts = []\n",
    "val_target_texts = []\n",
    "line_ix = 12000 # Stating after 10000\n",
    "for line in lines[line_ix:line_ix + 10]: # Getting 10 lines for validation\n",
    "    input_text, target_text, extra = line.split('\\t')\n",
    "    val_input_texts.append(input_text)\n",
    "    val_target_texts.append(target_text)\n",
    "\n",
    "# Prep the encoder\n",
    "val_encoder_input_data = np.zeros(\n",
    "    (len(val_input_texts), max([len(txt) for txt in val_input_texts\n",
    "                                ]), num_encoder_tokens),\n",
    "    dtype='float32')\n",
    "\n",
    "for i, input_text in enumerate(val_input_texts):\n",
    "    for t, char in enumerate(input_text):\n",
    "        val_encoder_input_data[i, t, input_token_index[char]] = 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "b1fcf63e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I saw him again.',\n",
       " 'I saw him first.',\n",
       " 'I saw it coming.',\n",
       " 'I saw it coming.',\n",
       " 'I saw it coming.',\n",
       " 'I saw one today.',\n",
       " 'I saw something.',\n",
       " 'I saw that, too.',\n",
       " 'I saw the movie.',\n",
       " 'I saw you there.']"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_input_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "39cc409f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-\n",
      "Input sentence: I saw him again.\n",
      "Decoded sentence: Ich habe einen Siegenerten.\n",
      "Ground Truth sentence: Ich habe ihn wieder gesehen.\n",
      "-\n",
      "Input sentence: I saw him first.\n",
      "Decoded sentence: Ich habe eine Schleren.\n",
      "Ground Truth sentence: Ich habe ihn zuerst gesehen.\n",
      "-\n",
      "Input sentence: I saw it coming.\n",
      "Decoded sentence: Ich habe einen Siegerehen.\n",
      "Ground Truth sentence: Ich habe es kommen sehen.\n",
      "-\n",
      "Input sentence: I saw it coming.\n",
      "Decoded sentence: Ich habe einen Siegerehen.\n",
      "Ground Truth sentence: Ich habe es geahnt.\n",
      "-\n",
      "Input sentence: I saw it coming.\n",
      "Decoded sentence: Ich habe einen Siegerehen.\n",
      "Ground Truth sentence: Ich ahnte es.\n",
      "-\n",
      "Input sentence: I saw one today.\n",
      "Decoded sentence: Ich habe eine Sie gefunden.\n",
      "Ground Truth sentence: Ich habe heute einen gesehen.\n",
      "-\n",
      "Input sentence: I saw something.\n",
      "Decoded sentence: Ich habe einen Schlesen gehen.\n",
      "Ground Truth sentence: Ich habe etwas gesehen.\n",
      "-\n",
      "Input sentence: I saw that, too.\n",
      "Decoded sentence: Ich habe eine Sie gesehen.\n",
      "Ground Truth sentence: Das habe ich auch gesehen.\n",
      "-\n",
      "Input sentence: I saw the movie.\n",
      "Decoded sentence: Ich habe Tom gesehen.\n",
      "Ground Truth sentence: Ich habe den Film gesehen.\n",
      "-\n",
      "Input sentence: I saw you there.\n",
      "Decoded sentence: Ich habe eine Sie gefunden.\n",
      "Ground Truth sentence: Ich sah dich dort.\n"
     ]
    }
   ],
   "source": [
    "for seq_index in range(10):\n",
    "    input_seq = val_encoder_input_data[seq_index:seq_index + 1]\n",
    "    decoded_sentence = decode_sequence(input_seq)\n",
    "    print('-')\n",
    "    print('Input sentence:', val_input_texts[seq_index])\n",
    "    print('Decoded sentence:', decoded_sentence[:-1])\n",
    "    print('Ground Truth sentence:', val_target_texts[seq_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aa6c948",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
