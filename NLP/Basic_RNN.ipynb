{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package gutenberg to\n",
      "[nltk_data]     C:\\Users\\nroy0\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\gutenberg.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['austen-emma.txt',\n",
       " 'austen-persuasion.txt',\n",
       " 'austen-sense.txt',\n",
       " 'bible-kjv.txt',\n",
       " 'blake-poems.txt',\n",
       " 'bryant-stories.txt',\n",
       " 'burgess-busterbrown.txt',\n",
       " 'carroll-alice.txt',\n",
       " 'chesterton-ball.txt',\n",
       " 'chesterton-brown.txt',\n",
       " 'chesterton-thursday.txt',\n",
       " 'edgeworth-parents.txt',\n",
       " 'melville-moby_dick.txt',\n",
       " 'milton-paradise.txt',\n",
       " 'shakespeare-caesar.txt',\n",
       " 'shakespeare-hamlet.txt',\n",
       " 'shakespeare-macbeth.txt',\n",
       " 'whitman-leaves.txt']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "# nltk.download('gutenberg')\n",
    "nltk.corpus.gutenberg.fileids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "aiw_raw_text = nltk.corpus.gutenberg.raw('carroll-alice.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "aiw_raw_text_lw = aiw_raw_text.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create mapping of unique chars to integers\n",
    "list_unique_chars = sorted(list(set(aiw_raw_text_lw)))\n",
    "dict_char_int_look_up = dict((char, i) for i, char in enumerate(list_unique_chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'\\n': 0,\n",
       " ' ': 1,\n",
       " '!': 2,\n",
       " '\"': 3,\n",
       " \"'\": 4,\n",
       " '(': 5,\n",
       " ')': 6,\n",
       " '*': 7,\n",
       " ',': 8,\n",
       " '-': 9,\n",
       " '.': 10,\n",
       " '1': 11,\n",
       " '5': 12,\n",
       " '6': 13,\n",
       " '8': 14,\n",
       " ':': 15,\n",
       " ';': 16,\n",
       " '?': 17,\n",
       " '[': 18,\n",
       " ']': 19,\n",
       " '_': 20,\n",
       " 'a': 21,\n",
       " 'b': 22,\n",
       " 'c': 23,\n",
       " 'd': 24,\n",
       " 'e': 25,\n",
       " 'f': 26,\n",
       " 'g': 27,\n",
       " 'h': 28,\n",
       " 'i': 29,\n",
       " 'j': 30,\n",
       " 'k': 31,\n",
       " 'l': 32,\n",
       " 'm': 33,\n",
       " 'n': 34,\n",
       " 'o': 35,\n",
       " 'p': 36,\n",
       " 'q': 37,\n",
       " 'r': 38,\n",
       " 's': 39,\n",
       " 't': 40,\n",
       " 'u': 41,\n",
       " 'v': 42,\n",
       " 'w': 43,\n",
       " 'x': 44,\n",
       " 'y': 45,\n",
       " 'z': 46}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_char_int_look_up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create mapping of unique intergers to chars\n",
    "dict_int_char_look_up = dict((i, char) for i, char in enumerate(list_unique_chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: '\\n',\n",
       " 1: ' ',\n",
       " 2: '!',\n",
       " 3: '\"',\n",
       " 4: \"'\",\n",
       " 5: '(',\n",
       " 6: ')',\n",
       " 7: '*',\n",
       " 8: ',',\n",
       " 9: '-',\n",
       " 10: '.',\n",
       " 11: '1',\n",
       " 12: '5',\n",
       " 13: '6',\n",
       " 14: '8',\n",
       " 15: ':',\n",
       " 16: ';',\n",
       " 17: '?',\n",
       " 18: '[',\n",
       " 19: ']',\n",
       " 20: '_',\n",
       " 21: 'a',\n",
       " 22: 'b',\n",
       " 23: 'c',\n",
       " 24: 'd',\n",
       " 25: 'e',\n",
       " 26: 'f',\n",
       " 27: 'g',\n",
       " 28: 'h',\n",
       " 29: 'i',\n",
       " 30: 'j',\n",
       " 31: 'k',\n",
       " 32: 'l',\n",
       " 33: 'm',\n",
       " 34: 'n',\n",
       " 35: 'o',\n",
       " 36: 'p',\n",
       " 37: 'q',\n",
       " 38: 'r',\n",
       " 39: 's',\n",
       " 40: 't',\n",
       " 41: 'u',\n",
       " 42: 'v',\n",
       " 43: 'w',\n",
       " 44: 'x',\n",
       " 45: 'y',\n",
       " 46: 'z'}"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_int_char_look_up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(144395, 47)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of characters in raw data and number of unique characters - LOWER\n",
    "n_chars = len(aiw_raw_text_lw)\n",
    "n_vocab = len(list_unique_chars)\n",
    "n_chars, n_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "144295"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# split the data in sequences of 100 (arb number)\n",
    "# convert the chars to integers based on dict_char_int\n",
    "\n",
    "seq_window = 100\n",
    "\n",
    "list_seq_windows_int = []\n",
    "list_seq_char_int = []\n",
    "\n",
    "for i in range(0, n_chars - seq_window, 1):\n",
    "    seq_in = aiw_raw_text_lw[i:i + seq_window]\n",
    "    seq_out = aiw_raw_text_lw[i + seq_window]\n",
    "    list_seq_windows_int.append([dict_char_int_look_up[char] for char in seq_in])\n",
    "    list_seq_char_int.append(dict_char_int_look_up[seq_out])\n",
    "    \n",
    "n_patterns = len(list_seq_windows_int)\n",
    "n_patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape X to be [samples, time steps, features]\n",
    "X = numpy.reshape(list_seq_windows_int, (n_patterns, seq_window, 1))\n",
    "\n",
    "# normalize\n",
    "X = X / float(n_vocab)\n",
    "\n",
    "# one hot encode the output variable\n",
    "y = np_utils.to_categorical(list_seq_char_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the LSTM model\n",
    "model = Sequential()\n",
    "model.add(LSTM(256, input_shape=(X.shape[1], X.shape[2])))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the checkpoint\n",
    "filepath=\"Basic_RNN_Weights/weights-improvement-{epoch:02d}-{loss:.4f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1128/1128 [==============================] - ETA: 0s - loss: 2.9817\n",
      "Epoch 00001: loss improved from inf to 2.98173, saving model to weights-improvement-01-2.9817.hdf5\n",
      "1128/1128 [==============================] - 422s 374ms/step - loss: 2.9817\n",
      "Epoch 2/20\n",
      "1128/1128 [==============================] - ETA: 0s - loss: 2.7732\n",
      "Epoch 00002: loss improved from 2.98173 to 2.77320, saving model to weights-improvement-02-2.7732.hdf5\n",
      "1128/1128 [==============================] - 391s 346ms/step - loss: 2.7732\n",
      "Epoch 3/20\n",
      "1128/1128 [==============================] - ETA: 0s - loss: 2.6665\n",
      "Epoch 00003: loss improved from 2.77320 to 2.66647, saving model to weights-improvement-03-2.6665.hdf5\n",
      "1128/1128 [==============================] - 439s 389ms/step - loss: 2.6665\n",
      "Epoch 4/20\n",
      "1128/1128 [==============================] - ETA: 0s - loss: 2.5920\n",
      "Epoch 00004: loss improved from 2.66647 to 2.59195, saving model to weights-improvement-04-2.5920.hdf5\n",
      "1128/1128 [==============================] - 745s 660ms/step - loss: 2.5920\n",
      "Epoch 5/20\n",
      "1128/1128 [==============================] - ETA: 0s - loss: 2.5318\n",
      "Epoch 00005: loss improved from 2.59195 to 2.53181, saving model to weights-improvement-05-2.5318.hdf5\n",
      "1128/1128 [==============================] - 841s 746ms/step - loss: 2.5318\n",
      "Epoch 6/20\n",
      "1128/1128 [==============================] - ETA: 0s - loss: 2.4744\n",
      "Epoch 00006: loss improved from 2.53181 to 2.47435, saving model to weights-improvement-06-2.4744.hdf5\n",
      "1128/1128 [==============================] - 825s 732ms/step - loss: 2.4744\n",
      "Epoch 7/20\n",
      "1128/1128 [==============================] - ETA: 0s - loss: 2.4244\n",
      "Epoch 00007: loss improved from 2.47435 to 2.42440, saving model to weights-improvement-07-2.4244.hdf5\n",
      "1128/1128 [==============================] - 850s 754ms/step - loss: 2.4244\n",
      "Epoch 8/20\n",
      "1128/1128 [==============================] - ETA: 0s - loss: 2.3759\n",
      "Epoch 00008: loss improved from 2.42440 to 2.37593, saving model to weights-improvement-08-2.3759.hdf5\n",
      "1128/1128 [==============================] - 853s 756ms/step - loss: 2.3759\n",
      "Epoch 9/20\n",
      "1128/1128 [==============================] - ETA: 0s - loss: 2.3325\n",
      "Epoch 00009: loss improved from 2.37593 to 2.33252, saving model to weights-improvement-09-2.3325.hdf5\n",
      "1128/1128 [==============================] - 852s 756ms/step - loss: 2.3325\n",
      "Epoch 10/20\n",
      "1128/1128 [==============================] - ETA: 0s - loss: 2.2897\n",
      "Epoch 00010: loss improved from 2.33252 to 2.28970, saving model to weights-improvement-10-2.2897.hdf5\n",
      "1128/1128 [==============================] - 3028s 3s/step - loss: 2.2897\n",
      "Epoch 11/20\n",
      "1128/1128 [==============================] - ETA: 0s - loss: 2.2497\n",
      "Epoch 00011: loss improved from 2.28970 to 2.24974, saving model to weights-improvement-11-2.2497.hdf5\n",
      "1128/1128 [==============================] - 601s 532ms/step - loss: 2.2497\n",
      "Epoch 12/20\n",
      "1128/1128 [==============================] - ETA: 0s - loss: 2.2100\n",
      "Epoch 00012: loss improved from 2.24974 to 2.20997, saving model to weights-improvement-12-2.2100.hdf5\n",
      "1128/1128 [==============================] - 367s 326ms/step - loss: 2.2100\n",
      "Epoch 13/20\n",
      "1128/1128 [==============================] - ETA: 0s - loss: 2.1742\n",
      "Epoch 00013: loss improved from 2.20997 to 2.17425, saving model to weights-improvement-13-2.1742.hdf5\n",
      "1128/1128 [==============================] - 412s 365ms/step - loss: 2.1742\n",
      "Epoch 14/20\n",
      "1128/1128 [==============================] - ETA: 0s - loss: 2.1386\n",
      "Epoch 00014: loss improved from 2.17425 to 2.13862, saving model to weights-improvement-14-2.1386.hdf5\n",
      "1128/1128 [==============================] - 457s 405ms/step - loss: 2.1386\n",
      "Epoch 15/20\n",
      "1128/1128 [==============================] - ETA: 0s - loss: 2.1058\n",
      "Epoch 00015: loss improved from 2.13862 to 2.10575, saving model to weights-improvement-15-2.1058.hdf5\n",
      "1128/1128 [==============================] - 470s 417ms/step - loss: 2.1058\n",
      "Epoch 16/20\n",
      "1128/1128 [==============================] - ETA: 0s - loss: 2.0697\n",
      "Epoch 00016: loss improved from 2.10575 to 2.06970, saving model to weights-improvement-16-2.0697.hdf5\n",
      "1128/1128 [==============================] - 511s 453ms/step - loss: 2.0697\n",
      "Epoch 17/20\n",
      " 892/1128 [======================>.......] - ETA: 1:57 - loss: 2.0376"
     ]
    }
   ],
   "source": [
    "model.fit(X, y, epochs=20, batch_size=128, callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the network weights\n",
    "filename = \"Basic_RNN_Weights/weights-improvement-16-2.0697.hdf5\"\n",
    "model.load_weights(filename)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pick a random seed\n",
    "start = numpy.random.randint(0, len(list_seq_windows_int)-1)\n",
    "pattern = list_seq_windows_int[start]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"t turned sulky, and would only say, 'i am older than\\nyou, and must know better'; and this alice woul\""
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed_char_list = []\n",
    "for _int in pattern:\n",
    "    for k,v in dict_char_int_look_up.items():\n",
    "        if v==_int:\n",
    "            seed_char_list.append(k)\n",
    "''.join(seed_char_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"t turned sulky, and would only say, 'i am older than\\nyou, and must know better'; and this alice woul\""
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# OR use int to char look-up\n",
    "''.join([dict_int_char_look_up[_int] for _int in pattern])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = numpy.reshape(pattern, (1, len(pattern), 1))\n",
    "x = x / float(n_vocab)\n",
    "prediction = model.predict(x, verbose=0)\n",
    "index = numpy.argmax(prediction)\n",
    "result = dict_int_char_look_up[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[35,\n",
       " 29,\n",
       " 25,\n",
       " 25,\n",
       " 1,\n",
       " 35,\n",
       " 34,\n",
       " 1,\n",
       " 40,\n",
       " 28,\n",
       " 25,\n",
       " 1,\n",
       " 40,\n",
       " 28,\n",
       " 38,\n",
       " 40,\n",
       " 25,\n",
       " 1,\n",
       " 40,\n",
       " 21,\n",
       " 39,\n",
       " 1,\n",
       " 35,\n",
       " 35,\n",
       " 1,\n",
       " 40,\n",
       " 28,\n",
       " 25,\n",
       " 1,\n",
       " 40,\n",
       " 35,\n",
       " 34,\n",
       " 25,\n",
       " 1,\n",
       " 40,\n",
       " 28,\n",
       " 1,\n",
       " 40,\n",
       " 28,\n",
       " 25,\n",
       " 1,\n",
       " 40,\n",
       " 25,\n",
       " 38,\n",
       " 1,\n",
       " 35,\n",
       " 26,\n",
       " 1,\n",
       " 40,\n",
       " 28,\n",
       " 25,\n",
       " 1,\n",
       " 40,\n",
       " 21,\n",
       " 38,\n",
       " 25,\n",
       " 1,\n",
       " 0,\n",
       " 21,\n",
       " 34,\n",
       " 24,\n",
       " 1,\n",
       " 40,\n",
       " 28,\n",
       " 25,\n",
       " 1,\n",
       " 43,\n",
       " 28,\n",
       " 38,\n",
       " 40,\n",
       " 1,\n",
       " 28,\n",
       " 34,\n",
       " 35,\n",
       " 34,\n",
       " 1,\n",
       " 21,\n",
       " 34,\n",
       " 1,\n",
       " 40,\n",
       " 28,\n",
       " 25,\n",
       " 1,\n",
       " 23,\n",
       " 35,\n",
       " 41,\n",
       " 32,\n",
       " 24,\n",
       " 1,\n",
       " 39,\n",
       " 35,\n",
       " 1,\n",
       " 40,\n",
       " 28,\n",
       " 25,\n",
       " 1,\n",
       " 40,\n",
       " 28,\n",
       " 38,\n",
       " 40]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'e'"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate characters\n",
    "for i in range(100):\n",
    "    x = numpy.reshape(pattern, (1, len(pattern), 1))\n",
    "    x = x / float(n_vocab)\n",
    "    prediction = model.predict(x, verbose=0)\n",
    "    index = numpy.argmax(prediction)\n",
    "    result = dict_int_char_look_up[index]\n",
    "    seq_in = [[value] for value in pattern]\n",
    "    dict_int_char_look_up.append(index)\n",
    "    pattern = pattern[1:len(pattern)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'toiee on the thrte tas oo the tone th the ter of the tare \\nand the whrt hnon an the could so the thr'"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''.join(seq_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'oiee on the thrte tas oo the tone th the ter of the tare \\nand the whrt hnon an the could so the thrt'"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\".join([dict_int_char_look_up[value] for value in pattern])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### OTHER CODE\n",
    "\n",
    "'''Example script to generate text from Nietzsche's writings.\n",
    "At least 20 epochs are required before the generated text\n",
    "starts sounding coherent.\n",
    "It is recommended to run this script on GPU, as recurrent\n",
    "networks are quite computationally intensive.\n",
    "If you try this script on new data, make sure your corpus\n",
    "has at least ~100k characters. ~1M is better.\n",
    "'''\n",
    "\n",
    "from __future__ import print_function\n",
    "from keras.callbacks import LambdaCallback\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.utils.data_utils import get_file\n",
    "import numpy as np\n",
    "import random\n",
    "import sys\n",
    "import io\n",
    "\n",
    "path = get_file(\n",
    "    'nietzsche.txt',\n",
    "    origin='https://s3.amazonaws.com/text-datasets/nietzsche.txt')\n",
    "with io.open(path, encoding='utf-8') as f:\n",
    "    text = f.read().lower()\n",
    "print('corpus length:', len(text))\n",
    "\n",
    "chars = sorted(list(set(text)))\n",
    "print('total chars:', len(chars))\n",
    "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))\n",
    "\n",
    "# cut the text in semi-redundant sequences of maxlen characters\n",
    "maxlen = 40\n",
    "step = 3\n",
    "sentences = []\n",
    "next_chars = []\n",
    "for i in range(0, len(text) - maxlen, step):\n",
    "    sentences.append(text[i: i + maxlen])\n",
    "    next_chars.append(text[i + maxlen])\n",
    "print('nb sequences:', len(sentences))\n",
    "\n",
    "print('Vectorization...')\n",
    "x = np.zeros((len(sentences), maxlen, len(chars)), dtype=np.bool)\n",
    "y = np.zeros((len(sentences), len(chars)), dtype=np.bool)\n",
    "for i, sentence in enumerate(sentences):\n",
    "    for t, char in enumerate(sentence):\n",
    "        x[i, t, char_indices[char]] = 1\n",
    "    y[i, char_indices[next_chars[i]]] = 1\n",
    "\n",
    "\n",
    "# build the model: a single LSTM\n",
    "print('Build model...')\n",
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(maxlen, len(chars))))\n",
    "model.add(Dense(len(chars), activation='softmax'))\n",
    "\n",
    "optimizer = RMSprop(lr=0.01)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer)\n",
    "\n",
    "\n",
    "def sample(preds, temperature=1.0):\n",
    "    # helper function to sample an index from a probability array\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)\n",
    "\n",
    "\n",
    "def on_epoch_end(epoch, _):\n",
    "    # Function invoked at end of each epoch. Prints generated text.\n",
    "    print()\n",
    "    print('----- Generating text after Epoch: %d' % epoch)\n",
    "\n",
    "    start_index = random.randint(0, len(text) - maxlen - 1)\n",
    "    for diversity in [0.2, 0.5, 1.0, 1.2]:\n",
    "        print('----- diversity:', diversity)\n",
    "\n",
    "        generated = ''\n",
    "        sentence = text[start_index: start_index + maxlen]\n",
    "        generated += sentence\n",
    "        print('----- Generating with seed: \"' + sentence + '\"')\n",
    "        sys.stdout.write(generated)\n",
    "\n",
    "        for i in range(400):\n",
    "            x_pred = np.zeros((1, maxlen, len(chars)))\n",
    "            for t, char in enumerate(sentence):\n",
    "                x_pred[0, t, char_indices[char]] = 1.\n",
    "\n",
    "            preds = model.predict(x_pred, verbose=0)[0]\n",
    "            next_index = sample(preds, diversity)\n",
    "            next_char = indices_char[next_index]\n",
    "\n",
    "            generated += next_char\n",
    "            sentence = sentence[1:] + next_char\n",
    "\n",
    "            sys.stdout.write(next_char)\n",
    "            sys.stdout.flush()\n",
    "        print()\n",
    "\n",
    "print_callback = LambdaCallback(on_epoch_end=on_epoch_end)\n",
    "\n",
    "model.fit(x, y,\n",
    "          batch_size=128,\n",
    "          epochs=6,\n",
    "          callbacks=[print_callback])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
