{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-02T15:43:13.620226Z",
     "start_time": "2022-04-02T15:43:00.580314Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "generator = pipeline(\"text-generation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-02T15:56:10.315643Z",
     "start_time": "2022-04-02T15:56:02.100287Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am a coral reef and I am severely affected by climate change. I am drowning. Please help me! Our efforts will only get louder. And that will be what we need on this very important water.\" The team of doctors on deck were all looking down at their bodies and seeing that their faces were blood-red.\n",
      "\n",
      "\"It's crazy how quickly you've got a baby in this way. I just wanted to take it out on a fishing team and look a little bleached,\" recalled John T. Moore. \"You can see that. It looks pretty horrible. I never thought I would see it like that. We're thinking for all the people around us. Help us to move on.\"\n",
      "\n",
      "The hospital was on her way back from being put on the emergency medical team to do her final rites. She was taking the first set of scales that came with my body, then using her hands, to wipe away the blood. She carried them to me and I sat with\n"
     ]
    }
   ],
   "source": [
    "prompt = \"I am a coral reef and I am severely affected by climate change. I am drowning. Please help me!\"\n",
    "\n",
    "outputs = generator(prompt, max_length=200)\n",
    "print(outputs[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-02T15:49:15.297583Z",
     "start_time": "2022-04-02T15:49:04.347368Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI, write a letter from a melting ice cap to the president.\n",
      "\n",
      "The ice cap is melting fast like a huge chunk of steel, but it's still moving, so the people of Minnesota are in need of icebreakers.\n",
      "\n",
      "\"The President is going to do whatever he needs to do to make sure nobody's in danger of having to leave their city for a week or two,\" he says.\n",
      "\n",
      "The government is looking for icebreakers just north of St. Louis for use with small vessels, but at this time they simply didn't get their funding yet, so they're looking to find the one they need.\n",
      "\n",
      "The government is sending out a $700,000 grant. They have only $1 million that can be used against the cost of building them but the cost will go forward. They hope they can prove that they have other ideas for the cost.\n",
      "\n",
      "\"We have been working with them for several months now because of that, and in the end\n"
     ]
    }
   ],
   "source": [
    "prompt = \"AI, write a letter from a melting ice cap to the president\"\n",
    "\n",
    "outputs = generator(prompt, max_length=200)\n",
    "print(outputs[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-02T15:49:25.563581Z",
     "start_time": "2022-04-02T15:49:16.561287Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HEy Putin, Stop the Ukrain war, and what Putin must do to end the bloodshed in Ukraine, The Guardian 4/27 An analysis of the fighting in the eastern Donetsk and Luhansk regions in the past three weeks by the Russian-backed separatists in the region's Donbass region. The government of Ukraine and Russia accused each other of a war crime and claimed that there is a direct line of contact between the government of the east and Russia. There have been at least six separate ceasefire violations, according to the separatists. Ukrainian military commanders made their way out of Deir ez-Zor and crossed into Luhansk. EPA 5/27 Russian leader Vladimir Putin speaks to reporters after a meeting with the Russian president at the Kremlin in Moscow 6/27 President Vladimir Putin with Russian deputy Prime Minister Sergei Ryabkov, the head of the regional federation of Ukraine's ruling political parties, during a meeting with a group of foreign ministers 7/27 US President Donald Trump and Russian President Vladimir\n"
     ]
    }
   ],
   "source": [
    "prompt = \"HEy Putin, Stop the Ukrain war\"\n",
    "\n",
    "outputs = generator(prompt, max_length=200)\n",
    "print(outputs[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-02T15:57:07.972969Z",
     "start_time": "2022-04-02T15:56:59.332235Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am hungry, help me get some food. Can someone help me get some medicine?\" She says with a laugh.\n",
      "\n",
      "\"No, just food…\" Jaune nods while reaching for food. This is only an item that can support one's needs.\n",
      "\n",
      "She picks up a bowl, shakes her head, and throws the bowl back. \"That's what I need… I'm hungry… I need something to get me started.\" Looking down, she sees that she's holding one leg.\n",
      "\n",
      "\"You know why do you keep coming back to the bathroom? Because you don't even have to clean. We get back in line to have food after we return home. So why do you always come back to work to get me some?\" Jaune asks with disbelief.\n",
      "\n",
      "\"Because you don't need… to fix anything…\" Ruby's body starts to hurt and Yang's body begins to feel a bit more tired from just sitting there as if she never had a drink. She looks\n"
     ]
    }
   ],
   "source": [
    "prompt = \"I am hungry, help me get some food.\"\n",
    "\n",
    "outputs = generator(prompt, max_length=200)\n",
    "print(outputs[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-02T15:51:46.205302Z",
     "start_time": "2022-04-02T15:51:42.890497Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "God is omnipresent. For when we ask Him to help us with life, He will not hesitate to ask for His help, or give him grace. Therefore, if we look at He's mercy, God is the one who saves us from death so that He may make our condition much better so that He may forgive us, and that we may live under His care.\n"
     ]
    }
   ],
   "source": [
    "prompt = \"God is omnipresent\"\n",
    "\n",
    "outputs = generator(prompt, max_length=200)\n",
    "print(outputs[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-02T15:52:32.177772Z",
     "start_time": "2022-04-02T15:52:23.104804Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Do you believe in God? Is there a Bible called 'The Bible'?,\" The Answer to that question will be sent to you in the form of a letter. This is a short answer, and I will let you decide for yourself the answer.\n",
      "\n",
      "In other words, I want you to read this little booklet with each word. When I gave this brief answer to the most general question in the Bible, I hoped you might ask it, and then that you might answer it. If you haven't heard of this booklet?\n",
      "\n",
      "The First Thing You Can Do About Your Problems\n",
      "\n",
      "Let us begin by telling you the things which you want to do about your troubles and problems in your life. Do you want to try to get back from your problems? Do you want to talk to people who have problems with your problems for days of time? One way for you to help yourself is by getting rid of any idea of failure like you always do. Some people have problems for more than\n"
     ]
    }
   ],
   "source": [
    "prompt = \"Do you believe in God?\"\n",
    "\n",
    "outputs = generator(prompt, max_length=200)\n",
    "print(outputs[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-02T15:53:38.430980Z",
     "start_time": "2022-04-02T15:53:34.291455Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Joey doesn't share food. He also does not like the idea of his friend asking questions.\n",
      "\n",
      "\"I just don't like being reminded like, this is my friend, and he likes the questions.\"\n",
      "\n",
      "He and his wife make sure there's a healthy amount of meat left.\n",
      "\n",
      "The former basketball star also doesn't watch the local football team play.\n",
      "\n",
      "Asked if the current game on TV is a bad idea, his reply is, \"No.\"\n"
     ]
    }
   ],
   "source": [
    "prompt = \"Joey doesn't share food.\"\n",
    "\n",
    "outputs = generator(prompt, max_length=100)\n",
    "print(outputs[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-02T16:07:56.579933Z",
     "start_time": "2022-04-02T16:07:54.007009Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I was walking and I saw the man following me. He was wearing an oversized black hood. I was scared. I didn't know what he was doing. We all watched. He was about to throw some water. I didn't know if I should get back to my car, or I'd just walk out of there and see whether I could get to him in time.\n"
     ]
    }
   ],
   "source": [
    "prompt = \"I was walking and I saw the man following me. He was wearing an oversized black hood. I was scared\"\n",
    "\n",
    "outputs = generator(prompt, max_length=100)\n",
    "print(outputs[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-02T16:01:33.365129Z",
     "start_time": "2022-04-02T16:01:25.165545Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello Ladies and Gentlemen, welcome to the Oscars. Who will be our best actor tonight? And who will be our greatest producer?\n",
      "\n",
      "You may already know that I'm one of the most famous people in Hollywood over the last 10 years. I worked with Roger Ailes once, from 2002 to 2008. I worked closely with Oscar voters at the Los Angeles Film Critics Guild Awards over numerous films before joining the Oscars (also working with SAG's Chris Hardwick and Steven Spielberg on The Imitation Game with David Oyelowo). And I'm part of a group of very talented producers — directors, executives and actors working in various fields from the screen to the film or television trade.\n",
      "\n",
      "And today, we will go over eight of the most celebrated directors in Hollywood. It's a group that includes two of the most accomplished independent filmmakers — John C. Reilly and John Landis. And one of the leaders — William Gibson is one of the leading voices in film as well.\n"
     ]
    }
   ],
   "source": [
    "prompt = \"Hello Ladies and Gentlemen, welcome to the Oscars. Who will be our best actor tonight?\"\n",
    "\n",
    "outputs = generator(prompt, max_length=200)\n",
    "print(outputs[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-02T16:02:40.679335Z",
     "start_time": "2022-04-02T16:02:31.633404Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Marhaba, welcome to Emirates.\n",
      "\n",
      "HAS, that's amazing that I thought you guys do exist. But when people ask us why, like how many different worlds there are, what, I'm sure that you'd say, you just want people to know that you're a guy with four kids, that you grew up in the United States. What do you think about being the youngest coach?\n",
      "\n",
      "I don't think that's even a question. People don't get that you can beat up women at Wimbledon when you're young and strong. I think we still have great girls. We're not fighting on the level that we were 20 years ago, we're fighting, what, just an absolute fighter, which gives me hope. No, that doesn't actually apply. There is a level of competition and a team environment. I am more comfortable playing female cricket, so there are definitely things I want to learn and I will pursue it if I feel like it.\n"
     ]
    }
   ],
   "source": [
    "prompt = \"Marhaba, welcome to Emirates\"\n",
    "\n",
    "outputs = generator(prompt, max_length=200)\n",
    "print(outputs[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-02T16:04:59.081712Z",
     "start_time": "2022-04-02T16:04:59.051674Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['XLNetLMHeadModel',\n",
       " 'TransfoXLLMHeadModel',\n",
       " 'ReformerModelWithLMHead',\n",
       " 'GPT2LMHeadModel',\n",
       " 'GPTNeoForCausalLM',\n",
       " 'OpenAIGPTLMHeadModel',\n",
       " 'CTRLLMHeadModel',\n",
       " 'TFXLNetLMHeadModel',\n",
       " 'TFTransfoXLLMHeadModel',\n",
       " 'TFGPT2LMHeadModel',\n",
       " 'TFOpenAIGPTLMHeadModel',\n",
       " 'TFCTRLLMHeadModel']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator.ALLOWED_MODELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-02T16:06:42.521317Z",
     "start_time": "2022-04-02T16:06:42.495642Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2LMHeadModel(\n",
       "  (transformer): GPT2Model(\n",
       "    (wte): Embedding(50257, 768)\n",
       "    (wpe): Embedding(1024, 768)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (6): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (7): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (8): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (9): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (10): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (11): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-04-02T16:16:50.614Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b61633c5436e4adf92c42f5fa23a8915",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.46k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db7b9256cfdd492fb2fe9a49a5408ce1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/10.7G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "generator_gpt_neo = pipeline('text-generation',\n",
    "                               model='EleutherAI/gpt-neo-2.7B')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
