{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DataLoader_Pytorch.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOGqIGRDQd/nQdsnkDenklY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/royn5618/Deep-Learning-Things/blob/main/NLP/DataLoader_Pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Reference :**\n",
        "https://pytorch.org/tutorials/beginner/basics/data_tutorial.html\n",
        "\n",
        "**Notes:**\n",
        "\n",
        "PyTorch provides two data primitives to allow using pre-loaded datasets or your own data: \n",
        "1. torch.utils.data.DataLoader\n",
        "2. torch.utils.data.Dataset\n",
        "\n",
        "\n",
        "# Loading a Dataset"
      ],
      "metadata": {
        "id": "gY1XsjLAZr5c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "training_data = datasets.FashionMNIST(\n",
        "    root=\"data\",  # root is the path where the train/test data is stored\n",
        "    train=True,  # bool: train specifies training or test dataset\n",
        "    download=True,  # downloads data from the internet if not available at root\n",
        "    transform=ToTensor()   # specify the feature and label transformations \n",
        ")\n",
        "\n",
        "test_data = datasets.FashionMNIST(\n",
        "    root=\"data\",\n",
        "    train=False, # False cz it is not the train set\n",
        "    download=True,\n",
        "    transform=ToTensor()\n",
        ")"
      ],
      "metadata": {
        "id": "ZGPxNPYWkmoL"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Creating a Custom Dataset for your files"
      ],
      "metadata": {
        "id": "y_8dlvhZZrH1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from torchvision.io import read_image\n",
        "\n",
        "class CustomImageDataset(Dataset):\n",
        "    def __init__(self, annotations_file, img_dir, \n",
        "                 transform=None, target_transform=None):\n",
        "        self.img_labels = pd.read_csv(annotations_file) \n",
        "        self.img_dir = img_dir\n",
        "        self.transform = transform\n",
        "        self.target_transform = target_transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.img_labels)  # ideally returns the length of the labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = os.path.join(self.img_dir, self.img_labels.iloc[idx, 0])\n",
        "        image = read_image(img_path)\n",
        "        label = self.img_labels.iloc[idx, 1]\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        if self.target_transform:\n",
        "            label = self.target_transform(label)\n",
        "        return image, label"
      ],
      "metadata": {
        "id": "M2A6G2fDk7R7"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preparing data for training with DataLoaders\n",
        "\n",
        "The **Dataset** retrieves our dataset’s features and labels one sample at a time.\n",
        "\n",
        "DataLoader allows us to pass samples in “minibatches”, reshuffle the data at every epoch to reduce model overfitting, and use Python’s multiprocessing to speed up data retrieval FOR training a model."
      ],
      "metadata": {
        "id": "0qT3mYcrgB-M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "train_dataloader = DataLoader(training_data, batch_size=64, shuffle=True)\n",
        "test_dataloader = DataLoader(test_data, batch_size=64, shuffle=True)"
      ],
      "metadata": {
        "id": "YY770DaHlAh5"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Iterate through the DataLoader\n",
        "\n",
        "Each iteration below returns a batch of train_features and train_labels (containing batch_size=64 features and labels respectively)."
      ],
      "metadata": {
        "id": "OKoUPOe5ro6Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Display image and label.\n",
        "train_features, train_labels = next(iter(train_dataloader))\n",
        "print(f\"Feature batch shape: {train_features.size()}\")\n",
        "print(f\"Labels batch shape: {train_labels.size()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NjCbwq8Vrpp6",
        "outputId": "24d903be-67a3-4e4a-f8bb-66cdc52e076b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feature batch shape: torch.Size([64, 1, 28, 28])\n",
            "Labels batch shape: torch.Size([64])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Noteice the 64 in the shape of the features and labels.\n",
        "\n",
        "## Visualize an image in the train batch"
      ],
      "metadata": {
        "id": "4mE6n2b6rzjw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "img = train_features[0].squeeze()\n",
        "label = train_labels[0]\n",
        "plt.imshow(img, cmap=\"gray\")\n",
        "plt.show()\n",
        "print(f\"Label: {label}\")"
      ],
      "metadata": {
        "id": "vvYaeRCOk7bo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "75af4178-f68d-4b72-9b70-b30e3ba2a19a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label: 3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Build a Model\n",
        "\n",
        "* The torch.nn namespace provides all the building blocks needed to build NNs\n",
        "* Every module in PyTorch subclasses the nn.Module\n",
        "* A neural network is a module itself that consists of other modules (layers)"
      ],
      "metadata": {
        "id": "7FSiGIjqtUjc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Get Device for Training"
      ],
      "metadata": {
        "id": "NE2hnYdqtijJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using {device} device\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nTkBUw42tW4I",
        "outputId": "0d99c0f2-2739-4669-cf34-bfefe5d39707"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cuda device\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import nn\n",
        "\n",
        "class NeuralNetwork(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(NeuralNetwork, self).__init__()\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.linear_relu_stack = nn.Sequential(\n",
        "            nn.Linear(28 * 28, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 10),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.flatten(x)\n",
        "        logits = self.linear_relu_stack(x)\n",
        "        return logits"
      ],
      "metadata": {
        "id": "xwdtXT3Jthy0"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = NeuralNetwork().to(device)\n",
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c1jABBSQuZA0",
        "outputId": "fccd56e3-6afc-4244-d09d-f22d3505c7dc"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NeuralNetwork(\n",
            "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "  (linear_relu_stack): Sequential(\n",
            "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (3): ReLU()\n",
            "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = torch.rand(1, 28, 28, device=device)  #input\n",
        "logits = model(X) # pass the input to the model. DO NOT CALL forward directly."
      ],
      "metadata": {
        "id": "iXw7zYYDub1N"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The model returns a 10-dimensional tensor with raw predicted values for each class. "
      ],
      "metadata": {
        "id": "JtFpLLyIvVSq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "logits  # raw predicted values"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J8pIn2xKxWFz",
        "outputId": "a977e420-0bc8-4939-a6ad-685324676f89"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.0345,  0.1406, -0.1050,  0.0666, -0.0758,  0.0412, -0.1476,  0.0120,\n",
              "         -0.1105, -0.0118]], device='cuda:0', grad_fn=<AddmmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred_probab = nn.Softmax(dim=1)(logits)  # prediction probabilities \n",
        "pred_probab\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2PSZqC4-vFsU",
        "outputId": "7cd85b88-a440-47d7-c6ae-eacdcfde5aea"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.0984, 0.1173, 0.0917, 0.1089, 0.0945, 0.1062, 0.0879, 0.1031, 0.0912,\n",
              "         0.1007]], device='cuda:0', grad_fn=<SoftmaxBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "highest prob -> 0.1173 in the 6th tensor (count starts from 0) or the 7th position"
      ],
      "metadata": {
        "id": "6KIAKOPjyDG3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = pred_probab.argmax(1)  # get the highest prob\n",
        "print(f\"Predicted class: {y_pred}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w5-d1TFTu5Kk",
        "outputId": "5ad24f82-e612-4cd8-a06d-cd43a8e52809"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted class: tensor([1], device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Optimizing Model HyperParameters\n",
        "\n",
        "Hyperparameters are adjustable parameters that let you control the model optimization process. Different hyperparameter values can impact model training and convergence rates\n",
        "* No of epochs\n",
        "* learning rate\n",
        "* batch size"
      ],
      "metadata": {
        "id": "tZg8LmV51Blf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = 1e-3\n",
        "batch_size = 64\n",
        "epochs = 5"
      ],
      "metadata": {
        "id": "e1_18ROc1gLv"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Once we set our hyperparameters, we can then train and optimize our model with an optimization loop. Each iteration of the optimization loop is called an epoch.\n",
        "\n",
        "Each epoch consists of two main parts:\n",
        "* The Train Loop - iterate over the training dataset and try to converge to optimal parameters.\n",
        "\n",
        "* The Validation/Test Loop - iterate over the test dataset to check if model performance is improving."
      ],
      "metadata": {
        "id": "vL_ZrLi41oFW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Loss function** measures the degree of dissimilarity of obtained result to the target value, and it is the loss function that we want to minimize during training. \n",
        "\n",
        "**Optimization** is the process of adjusting model parameters to reduce model error in each training step, ie. the **loss**.\n",
        "\n"
      ],
      "metadata": {
        "id": "iER5IJ7P1zl4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate) # initializing stochastic gradient descent"
      ],
      "metadata": {
        "id": "BfYUk4Pb1J-l"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train Loop\n",
        "\n",
        "loops over our optimization code\n",
        "\n",
        "Inside the training loop, optimization happens in three steps:\n",
        "1. Call optimizer.zero_grad() to reset the gradients of model parameters. Gradients by default add up; to prevent double-counting, we explicitly zero them at each iteration.\n",
        "2. Backpropagate the prediction loss with a call to loss.backward(). PyTorch deposits the gradients of the loss w.r.t. each parameter.\n",
        "3. Once we have our gradients, we call optimizer.step() to adjust the parameters by the gradients collected in the backward pass.\n",
        "\n"
      ],
      "metadata": {
        "id": "AVO6rzYO2qrP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_loop(dataloader, model, loss_fn, optimizer):\n",
        "    size = len(dataloader.dataset)\n",
        "    for batch, (X, y) in enumerate(dataloader):\n",
        "        # Compute prediction and loss\n",
        "        pred = model(X.to(device)) # calls the model for predictions\n",
        "        loss = loss_fn(pred, y.to(device)) # gets the loss by comparing the prediction(pred) and the actual(y)\n",
        "\n",
        "        # Backpropagation\n",
        "        optimizer.zero_grad() # step 1 - resets the gradient\n",
        "        loss.backward() # step 2 - propagates the error backward\n",
        "        optimizer.step() # step 3 - Performs a single optimization step\n",
        "\n",
        "        if batch % 100 == 0:\n",
        "            loss, current = loss.item(), batch * len(X)\n",
        "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n"
      ],
      "metadata": {
        "id": "Ly26oXlt2sBD"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test Loop\n",
        "\n",
        "evaluates the model’s performance against our test data"
      ],
      "metadata": {
        "id": "mUFNYoh19jGw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def test_loop(dataloader, model, loss_fn):\n",
        "    size = len(dataloader.dataset)\n",
        "    num_batches = len(dataloader)\n",
        "    test_loss, correct = 0, 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for X, y in dataloader:\n",
        "            pred = model(X.to(device))\n",
        "            test_loss += loss_fn(pred, y.to(device)).item()\n",
        "            correct += (pred.argmax(1) == y.to(device)).type(torch.float).sum().item()\n",
        "\n",
        "    test_loss /= num_batches\n",
        "    correct /= size\n",
        "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
      ],
      "metadata": {
        "id": "PwB-g8t-1dHp"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Run to train and evluate the model"
      ],
      "metadata": {
        "id": "hUqxpa6eBqzH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for t in range(epochs):\n",
        "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
        "    train_loop(train_dataloader, model, loss_fn, optimizer)\n",
        "    test_loop(test_dataloader, model, loss_fn)\n",
        "print(\"Done!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "35Szz4Xe1E6n",
        "outputId": "7f80ac22-e4f9-4c9a-f223-c3425de689df"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            "-------------------------------\n",
            "loss: 0.719414  [    0/60000]\n",
            "loss: 1.065405  [ 6400/60000]\n",
            "loss: 0.786717  [12800/60000]\n",
            "loss: 0.847479  [19200/60000]\n",
            "loss: 0.794212  [25600/60000]\n",
            "loss: 0.936504  [32000/60000]\n",
            "loss: 0.740786  [38400/60000]\n",
            "loss: 0.886059  [44800/60000]\n",
            "loss: 0.766301  [51200/60000]\n",
            "loss: 0.833832  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 68.4%, Avg loss: 0.855189 \n",
            "\n",
            "Epoch 2\n",
            "-------------------------------\n",
            "loss: 0.778386  [    0/60000]\n",
            "loss: 0.836157  [ 6400/60000]\n",
            "loss: 0.931459  [12800/60000]\n",
            "loss: 0.925169  [19200/60000]\n",
            "loss: 0.789799  [25600/60000]\n",
            "loss: 0.899586  [32000/60000]\n",
            "loss: 0.892853  [38400/60000]\n",
            "loss: 0.870776  [44800/60000]\n",
            "loss: 0.802944  [51200/60000]\n",
            "loss: 0.782164  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 70.1%, Avg loss: 0.815768 \n",
            "\n",
            "Epoch 3\n",
            "-------------------------------\n",
            "loss: 0.709200  [    0/60000]\n",
            "loss: 0.675803  [ 6400/60000]\n",
            "loss: 0.759618  [12800/60000]\n",
            "loss: 0.721134  [19200/60000]\n",
            "loss: 0.764316  [25600/60000]\n",
            "loss: 0.784264  [32000/60000]\n",
            "loss: 0.757742  [38400/60000]\n",
            "loss: 0.848689  [44800/60000]\n",
            "loss: 0.822174  [51200/60000]\n",
            "loss: 0.828199  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 71.1%, Avg loss: 0.785436 \n",
            "\n",
            "Epoch 4\n",
            "-------------------------------\n",
            "loss: 0.708339  [    0/60000]\n",
            "loss: 0.892802  [ 6400/60000]\n",
            "loss: 0.859460  [12800/60000]\n",
            "loss: 0.707042  [19200/60000]\n",
            "loss: 0.701749  [25600/60000]\n",
            "loss: 0.875728  [32000/60000]\n",
            "loss: 0.577991  [38400/60000]\n",
            "loss: 0.888625  [44800/60000]\n",
            "loss: 0.826206  [51200/60000]\n",
            "loss: 0.788311  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 72.1%, Avg loss: 0.759398 \n",
            "\n",
            "Epoch 5\n",
            "-------------------------------\n",
            "loss: 0.832282  [    0/60000]\n",
            "loss: 0.770015  [ 6400/60000]\n",
            "loss: 0.750295  [12800/60000]\n",
            "loss: 0.776699  [19200/60000]\n",
            "loss: 0.801891  [25600/60000]\n",
            "loss: 0.697373  [32000/60000]\n",
            "loss: 0.810564  [38400/60000]\n",
            "loss: 0.663725  [44800/60000]\n",
            "loss: 0.774898  [51200/60000]\n",
            "loss: 0.940012  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 73.6%, Avg loss: 0.737287 \n",
            "\n",
            "Done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Save and Load the Model"
      ],
      "metadata": {
        "id": "5CZkHpoFG-N7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision.models as models\n",
        "torch.save(model.state_dict(), 'model_weights.pth')"
      ],
      "metadata": {
        "id": "6eg03e1EEUs4"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_state_dict(torch.load('model_weights.pth'))\n",
        "model.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SD_0PR8GGzWQ",
        "outputId": "56e0bf7e-4be1-4597-b450-9b8b0904d2a1"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "NeuralNetwork(\n",
              "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
              "  (linear_relu_stack): Sequential(\n",
              "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
              "    (1): ReLU()\n",
              "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
              "    (3): ReLU()\n",
              "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    }
  ]
}